{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-Source RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the environment variables\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia Tool : To search about the topic on Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=2000)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Rohit Sharma\n",
      "Summary: Rohit Sharma (born 30 April 1987) is an Indian international cricketer who currently plays for and captains the India national cricket team in Test and ODI matches. He previously captained in T20 matches and in the country's 2024 T20 World Cup win after which he retired from T20s in June. He is considered as one of the best batsmen of his generation and one of the greatest white-ball opening batters of all time. \n",
      "He holds several batting records which famously include most runs in T20 Internationals, most sixes in international cricket, most double centuries in ODI cricket (3), most centuries at Cricket World Cups (7) and joint most hundreds in Twenty20 Internationals (5). He is the first player to score 5 T20I centuries. He also holds the world record for the highest individual score (264) in a One Day International (ODI) match and is the only player to have scored three double-centuries in ODIs and also holds the record for scoring most hundreds (five) in a single Cricket World Cup, for which he won the ICC Men's ODI Cricketer of the Year award in 2019. He is the only player to win 50 matches as captain in T20Is.\n",
      "He plays for Mumbai Indians and Mumbai cricket team in Indian Premier League (IPL) and domestic cricket respectively. He formerly captained Mumbai Indians and the team has won 5 Indian Premier League titles in 2013, 2015, 2017, 2019 and 2020 under him, making him the most successful captain in IPL history, sharing this record with MS Dhoni. With India, Rohit Sharma was a member of the team that won the 2007 T20 World Cup, and the 2013 ICC Champions Trophy, where he played in the finals of both tournaments. He is also one of two players who have played in every edition of the T20 World Cup, from the inaugural edition in 2007 to the latest one in 2024. He is the only Indian player to win two T20 World Cups. He became the second Indian captain to win a T20 World Cup, when he led India to win the 2024 T20 World Cup.\n",
      "He has received\n"
     ]
    }
   ],
   "source": [
    "print(wiki_tool.invoke({\"query\":\"Rohit Sharma\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: wikipedia\n",
      "Description: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "args schema: {'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n",
      "returns directly?: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name: {wiki_tool.name}\")\n",
    "print(f\"Description: {wiki_tool.description}\")\n",
    "print(f\"args schema: {wiki_tool.args}\")\n",
    "print(f\"returns directly?: {wiki_tool.return_direct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reteiver tool : Creating tool to retrieve information about langsmith, store it in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_chroma.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\",model_kwargs={'device': 'cpu'},encode_kwargs={'normalize_embeddings': False})\n",
    "\n",
    "chroma_db = Chroma('chroma_vectorstore',embedding_function=embedding)\n",
    "chroma_db.add_documents(documents=documents,embedding=embedding)\n",
    "\n",
    "retriever=chroma_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever=retriever,\n",
    "                                     name=\"langsmith_search\",\n",
    "                                     description=\"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arvix Tool : Create a tool which search the arvix for specific research paper or related thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=3,doc_content_chars_max=500)\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2023-09-19\\nTitle: Attention Is Not All You Need Anymore\\nAuthors: Zhe Chen\\nSummary: In recent years, the popular Transformer architecture has achieved great\\nsuccess in many application areas, including natural language processing and\\ncomputer vision. Many existing works aim to reduce the computational and memory\\ncomplexity of the self-attention mechanism in the Transformer by trading off\\nperformance. However, performance is key for the continuing success of the\\nTransformer. In this pap'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_tool.invoke({'query':\"Give me the summary of the attention all you need research paper\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [arxiv_tool,wiki_tool,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "from langchain_groq import ChatGroq\n",
    "model_id = \"llama-3.3-70b-versatile\"\n",
    "model = ChatGroq(\n",
    "    model=model_id,\n",
    "    temperature=0.5,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\env_langchain_tutorial\\lib\\site-packages\\langsmith\\client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.agents import create_react_agent,AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer questions about Langchain, I need to consider what Langchain is and where I can find information about it. Langchain is a framework for building applications that utilize large language models, so I should look for information related to this topic.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Langchain\u001b[0m\u001b[33;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\u001b[0m\u001b[32;1m\u001b[1;3mThought: The Wikipedia page provides a general overview of LangChain, but it may not have the most up-to-date or detailed information. To get more specific information about LangChain, I should try searching for it on a platform that specializes in language models or AI.\n",
      "\n",
      "Action: arxiv\n",
      "Action Input: Langchain\u001b[0m\u001b[36;1m\u001b[1;3mPublished: 2023-08-15\n",
      "Title: From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?\n",
      "Authors: Rodrigo Pedro, Daniel Castro, Paulo Carreira, Nuno Santos\n",
      "Summary: Large Language Models (LLMs) have found widespread applications in various\n",
      "domains, including web applications, where they facilitate human interaction\n",
      "via chatbots with natural language interfaces. Internally, aided by an\n",
      "LLM-integration middleware such as Langchain, user prompts are transl\u001b[0m\u001b[32;1m\u001b[1;3mThought: The arxiv search results provide some information about LangChain, but they seem to be focused on a specific research paper related to security vulnerabilities in LLM-integrated web applications. While this is interesting, it may not provide a comprehensive overview of LangChain. To get more information about LangChain, I should try searching for it on a platform that specializes in language models or AI, or look for a more general overview of the framework.\n",
      "\n",
      "Action: langsmith_search\n",
      "Action Input: Langchain\u001b[0m\u001b[38;5;200m\u001b[1;3mLangSmith + LangChain OSSLangSmith integrates seamlessly with LangChain's open source frameworks langchain and langgraph, with no extra instrumentation needed.If you're already using either of these, see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "LangSmith is a standalone platform that can be used on it's own no matter how you're creating your LLM applicatons.\n",
      "In this tutorial, we'll walk you though logging your first trace in LangSmith using the LangSmith SDK and running an evaluation to measure the performance of your application. This example uses the OpenAI API, however you can use your provider of choice.\n",
      "1. Install LangSmith​\n",
      "PythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\n",
      "2. Create an API key​\n",
      "To create an API key head to the Settings page. Then click Create API Key.\n",
      "3. Set up your environment​\n",
      "\n",
      "Click the link printed out by your evaluation run to access the LangSmith experiments UI,\n",
      "and explore the results of your evaluation.\n",
      "Learn more about evaluation in the tutorials, conceptual guide, and how-to guides.\n",
      "Was this page helpful?You can leave detailed feedback on GitHub.NextObservability tutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. View your trace6. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.\n",
      "\n",
      "Get started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceQuick StartOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "With LangSmith you can:\n",
      "\n",
      "PythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\n",
      "2. Create an API key​\n",
      "To create an API key head to the Settings page. Then click Create API Key.\n",
      "3. Set up your environment​\n",
      "Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key>export OPENAI_API_KEY=<your-openai-api-key>\n",
      "4. Log your first trace​\n",
      "We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n",
      "how to use traceable(). See more on the Annotate code for tracing page.\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. It is a language model integration framework that can be used to build various applications, including document analysis and summarization, chatbots, and code analysis. LangChain integrates seamlessly with LangSmith, a platform for building production-grade LLM applications, and can be used with other frameworks such as LangGraph. LangChain provides a way to closely monitor and evaluate LLM applications, allowing developers to ship quickly and with confidence.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Langchain',\n",
       " 'output': 'LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. It is a language model integration framework that can be used to build various applications, including document analysis and summarization, chatbots, and code analysis. LangChain integrates seamlessly with LangSmith, a platform for building production-grade LLM applications, and can be used with other frameworks such as LangGraph. LangChain provides a way to closely monitor and evaluate LLM applications, allowing developers to ship quickly and with confidence.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_react_agent(llm=model,tools=tools,prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor.invoke({\"input\":\"Langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_langchain_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
